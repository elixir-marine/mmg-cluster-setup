


# CHECK THE CORRECTNESS ACCORDING TO THE NEEDS/PREFERENCES:

# pouta.csc.fi -> Project -> Compute -> Access & Security -> the service called "Identity"
osAuthName: https://pouta.csc.fi:5001/v2.0

# The name of your CSC project
projectName: Project_2000053

# pouta.csc.fi -> Project -> Network -> Networks -> the name of your project network
networkName: project_2000053
# pouta.csc.fi -> Project -> Network -> Networks -> your project network -> ID in Network Overview
networkId: 88d1d9e6-8038-4258-9e50-91ced4fee75c

bastionFlavor: standard.xlarge
bastionMachineName: bastion_host
bastionSecGroupName: bastion-metapipe

clusterName: csc-metapipe-cluster
clusterKeyName: my_cluster_key

serverGroupAntiAffinity: true

# "swVolumeSize" = must have size of SW (META-pipe) + some extra gigabytes
swVolumeSize: 75
swNfcShared: false

master:
  flavor: hpc-gen1.16core
  nfsSwTmpVolumeSize: 300

# Choose (leave uncommented) exactly 1 of the node groups, and comment the unused one.
nodeGroups:
  - regularHddNodes
#  - ioHddSsdNodes

regularHddNodes:
  numNodes: 2
  flavor: hpc-gen2.48core

ioHddSsdNodes: # (SDD volume size is defined in the name of an io-flavor)
  numNodes: 6
  flavor: io.700GB

# SPARK CONFIGURATION VARIABLES: These values are meant to be set before running "create-cluster" command.
# Changing them when cluster already exists is ok but not recommended (may have to use the 'dev' launch command).
# For the next 3 values - x: manual value, 0: default number from Flavor.
sparkMasterVmCores: 0
sparkMasterVmRam: 0
sparkWorkerVmCores: 0
# x: manual value, 0: default algorithm (flavorRam<=15: flavorRam-1, 15<=flavorRam<55: flavorRam-2, 55<flavorRam<255: flavorRam-3, flavorRam>=255: flavorRam-4)
sparkWorkerVmRam: 0
# x: manual value, 0: default algorithm (sparkWorkerVmCores / 2)
sparkExecutorCores: 4
# x: manual value, 0: default algorithm (sum of all worker-nodes' cores * 4), -1: disabled / not in use
sparkNumPartitions: 0

# THESE ARE REQUIRED FOR META-pipe EXECUTION:
swJobTag: csc-AAA
swArtifactsAuthRequired: true
swArtifactsUsername:
swArtifactsPassword:
swArtifactsFilesExec: https://artifacts.sfb.uit.no/jenkins/newpan_tools/67/workflow-assembly-0.1-SNAPSHOT.jar
swArtifactsFileDepsArc: https://artifacts.sfb.uit.no/jenkins/newpan_tools_dependencies/20/metapipe-dependencies.tar.gz
swArtifactsFilesEtc:
#  -

# Maximal number of log files in the "logs" folder.
# For a limited number of logs, set to a positive number. For no logs, set to 0. For unlimited number of logs, set to -1.
maxLogs: -1




# SHOULD NOT OR MIGHT NOT HAVE NEED TO CHANGE:

regionName: regionOne
bastionAvailZone: nova

bastionKeyName: my_bastion_key

# Admins' IPs. The IP of the machine that runs the tool will be added automatically during cluster creation.
# Syntax: X.X.X.X (single IP), X.X.X.X-X.X.X.X (IP range)
# Everyone:                           0.0.0.0-255.255.255.255
# UiT network:                        129.242.0.0-129.242.255.255
# CSC network:                        86.50.0.0-86.50.255.255, 193.166.0.0-193.166.255.255, 193.167.0.0-193.167.255.255
# CSC portal on DataCenter Finland:   89.250.59.9
ipAdmins:

ipCheck: http://checkip.amazonaws.com




# DO NOT CHANGE!

userName: cloud-user

clusterKeyFileName: id_rsa_csc_cluster

imageDefault: CentOS-7.0

# This 4 variables are set by the tool
bastionFloatingIpId:
securityGroupId:
serverGroupId:
swDiskID:

xternFiles:
  ansibleScript: pouta-ansible-cluster
  sw: sw_files
  config: config.yml
  thisJar: Metapipe-cPouta.jar
  diskHelper: _disk.sh
  ansibleClusterVars: cluster_vars.yaml
  ansibleClusterVarsTemplate: cluster_vars.yaml.template
  disablePasswordAuth: _disablePasswordAuth.sh
  sparkSetupScriptInit: _init.sh
  sparkSetupScript: _setup_cluster.sh
  clusterTestScript: cluster_test.py

swInitScript: _init.sh
swPrepareScript: _prepare.sh
swTestScript: _test.sh
swLaunchScript: _run.sh
swStopScript: _stop.sh
swExecutable: workflow-assembly-0.1-SNAPSHOT.jar

# Important dirs, META-pipe location on cluster, NFS shared dirs
nfsSwMainVolumeMount: /export/sw_main
nfsSwTmpVolumeMount: /export/sw_tmp
swFilesDirName: sw
sparkFilesDir: /export/sw_tmp
